Z <- max(x) + 0.05 * diff(range(x))
nbr <- 7
cat("A =", A, "\n")
cat("Z =", Z, "\n")
# Plot the histogram
hx <- hist(x, breaks = seq(A, Z, length = nbr + 1), freq = FALSE,
main = "Histogram of CDrate", xlab = "CDrate")
hx_f <- stepfun(hx$breaks, c(0, hx$density, 0))
# Evaluate the histogram estimator at each data point
f_hat <- hx_f(x)
# Add the points to the plot
plot(hx, freq = FALSE, main = "Histogram of CDrate", xlab = "CDrate")
points(x, f_hat, col = "blue", pch = 19, cex = 0.5)
legend(x = 7.5, y = 1.3, "f_hat(x_i)", col = "blue", pch = 19)
# Calculate bin width
b <- (Z - A) / nbr
n <- length(x)
# Calculate the leave-one-out estimates
f_loo <- (n / (n - 1)) * f_hat - 1 / ((n - 1) * b)
# Add the points to the plot
plot(hx, freq = FALSE, main = "Histogram with Full and LOO Densities", xlab = "CDrate")
points(x, f_hat, col = "blue", pch = 19, cex = 0.5)
points(x, f_loo, col = "red", pch = 4, cex = 0.5)
legend(x = 7.5, y = 1.3, c("f_hat(x_i)", "f_loo(x_i)"), col = c("blue", "red"), pch = c(19, 4))
# We only take the log of positive values. If f_loo is 0, log(f_loo) is -Inf.
# This happens when a point is the only one in its bin.
looCV_log_lik_7 <- sum(log(f_loo[f_loo > 0]))
cat("Leave-one-out log-likelihood for nbr=7:", looCV_log_lik_7)
n <- length(x)
nbr_values <- 1:15
looCV_log_lik_nbr <- numeric(length(nbr_values))
for (i in seq_along(nbr_values)) {
current_nbr <- nbr_values[i]
b <- (Z - A) / current_nbr
# Create histogram object
hx <- hist(x, breaks = seq(A, Z, length = current_nbr + 1), plot = FALSE)
# Create step function
hx_f <- stepfun(hx$breaks, c(0, hx$density, 0))
# Calculate f_hat and f_loo
f_hat <- hx_f(x)
f_loo <- (n / (n - 1)) * f_hat - 1 / ((n - 1) * b)
# Calculate and store looCV log-likelihood
looCV_log_lik_nbr[i] <- sum(log(f_loo[f_loo > 0]))
}
# Plot the results
plot(nbr_values, looCV_log_lik_nbr, type = "b", pch = 19,
xlab = "Number of Bins (nbr)", ylab = "LOO Log-Likelihood",
main = "LOO Cross-Validation for Number of Bins")
# Find the optimal nbr
optimal_nbr <- nbr_values[which.max(looCV_log_lik_nbr)]
abline(v = optimal_nbr, col = "red", lty = 2)
legend("bottomleft", legend = paste("Optimal nbr =", optimal_nbr), col = "red", lty = 2)
hist(x, breaks = seq(A, Z, length = optimal_nbr + 1), freq = FALSE,
main = paste("Optimal Histogram (nbr =", optimal_nbr, ")"),
xlab = "CDrate")
b_values <- seq((Z - A) / 15, (Z - A) / 1, length = 30)
looCV_log_lik_b <- numeric(length(b_values))
for (i in seq_along(b_values)) {
current_b <- b_values[i]
# Create histogram object with specified bin width
hx <- hist(x, breaks = seq(A, Z + current_b, by = current_b), plot = FALSE)
# Create step function
hx_f <- stepfun(hx$breaks, c(0, hx$density, 0))
# Calculate f_hat and f_loo
f_hat <- hx_f(x)
f_loo <- (n / (n - 1)) * f_hat - 1 / ((n - 1) * current_b)
# Calculate and store looCV log-likelihood
looCV_log_lik_b[i] <- sum(log(f_loo[f_loo > 0]))
}
# Plot the results
plot(b_values, looCV_log_lik_b, type = "b", pch = 19,
xlab = "Bin Width (b)", ylab = "LOO Log-Likelihood",
main = "LOO Cross-Validation for Bin Width")
# Find the optimal b
optimal_b <- b_values[which.max(looCV_log_lik_b)]
abline(v = optimal_b, col = "red", lty = 2)
legend("topright", legend = paste("Optimal b =", round(optimal_b, 3)), col = "red", lty = 2)
hx_optimal_b <- hist(x, breaks = seq(A, Z + optimal_b, by = optimal_b), plot = FALSE)
plot(hx_optimal_b, freq = FALSE,
main = paste("Optimal Histogram (b =", round(optimal_b, 3), ")"),
xlab = "CDrate")
#We will use the same method as before
A <- min(x) - 0.05 * diff(range(x))
Z <- max(x) + 0.05 * diff(range(x))
b_values <- seq((Z - A) / 15, (Z - A) / 1, length = 30)
looCV_log_lik_b <- numeric(length(b_values))
for (i in seq_along(b_values)) {
current_b <- b_values[i]
# Create histogram object with specified bin width
hx <- hist(x, breaks = seq(A, Z + current_b, by = current_b), plot = FALSE)
# Create step function
hx_f <- stepfun(hx$breaks, c(0, hx$density, 0))
# Calculate f_hat and f_loo
f_hat <- hx_f(x)
f_loo <- (n / (n - 1)) * f_hat - 1 / ((n - 1) * current_b)
# Calculate and store looCV log-likelihood
looCV_log_lik_b[i] <- sum(log(f_loo[f_loo > 0]))
}
# Plot the results
plot(b_values, looCV_log_lik_b, type = "b", pch = 19,
xlab = "Bin Width (b)", ylab = "LOO Log-Likelihood",
main = "LOO Cross-Validation for Bin Width")
# Find the optimal b
optimal_b <- b_values[which.max(looCV_log_lik_b)]
abline(v = optimal_b, col = "red", lty = 2)
legend("bottomright", legend = paste("Optimal b =", round(optimal_b, 3)), col = "red", lty = 2)
#We will use the same method as before
A <- min(x) - 0.05 * diff(range(x))
Z <- max(x) + 0.05 * diff(range(x))
b_values <- seq((Z - A) / 15, (Z - A) / 1, length = 30)
looCV_log_lik_b <- numeric(length(b_values))
for (i in seq_along(b_values)) {
current_b <- b_values[i]
# Create histogram object with specified bin width
hx <- hist(x, breaks = seq(A, Z + current_b, by = current_b), plot = FALSE)
# Create step function
hx_f <- stepfun(hx$breaks, c(0, hx$density, 0))
# Calculate f_hat and f_loo
f_hat <- hx_f(x)
f_loo <- (n / (n - 1)) * f_hat - 1 / ((n - 1) * current_b)
# Calculate and store looCV log-likelihood
looCV_log_lik_b[i] <- sum(log(f_loo[f_loo > 0]))
}
# Plot the results
plot(b_values, looCV_log_lik_b, type = "b", pch = 19,
xlab = "Bin Width (b)", ylab = "LOO Log-Likelihood",
main = "LOO Cross-Validation for Bin Width")
# Find the optimal b
optimal_b <- b_values[which.max(looCV_log_lik_b)]
abline(v = optimal_b, col = "red", lty = 2)
legend("bottomleft", legend = paste("Optimal b =", round(optimal_b, 3)), col = "red", lty = 2)
#We will use the same method as before
A <- min(x) - 0.05 * diff(range(x))
Z <- max(x) + 0.05 * diff(range(x))
b_values <- seq((Z - A) / 15, (Z - A) / 1, length = 30)
looCV_log_lik_b <- numeric(length(b_values))
for (i in seq_along(b_values)) {
current_b <- b_values[i]
# Create histogram object with specified bin width
hx <- hist(x, breaks = seq(A, Z + current_b, by = current_b), plot = FALSE)
# Create step function
hx_f <- stepfun(hx$breaks, c(0, hx$density, 0))
# Calculate f_hat and f_loo
f_hat <- hx_f(x)
f_loo <- (n / (n - 1)) * f_hat - 1 / ((n - 1) * current_b)
# Calculate and store looCV log-likelihood
looCV_log_lik_b[i] <- sum(log(f_loo[f_loo > 0]))
}
# Plot the results
plot(b_values, looCV_log_lik_b, type = "b", pch = 19,
xlab = "Bin Width (b)", ylab = "LOO Log-Likelihood",
main = "LOO Cross-Validation for Bin Width")
# Find the optimal b
optimal_b <- b_values[which.max(looCV_log_lik_b)]
abline(v = optimal_b, col = "red", lty = 2)
legend("topright", legend = paste("Optimal b =", round(optimal_b, 3)), col = "red", lty = 2)
# Generate 100 observations from f(x) = (3/4)N(x; m = 0, s = 1) +(1/4) N(x; m = 3/2, s = 1/3)
set.seed(123)
n <- 100
mu <- c(0,3/2)
sigma <- c(1,1/3)
alpha <- c(3/4,1/4)
x <- sim.mixt(n=n, k=2, mu=mu, sigma=sigma, alpha=alpha)
f_x <- graph.mixt(k=2, mu=mu, sigma=sigma, alpha=alpha, graphic = F)
#We will use the same method as before
A <- min(x) - 0.05 * diff(range(x))
Z <- max(x) + 0.05 * diff(range(x))
b_values <- seq((Z - A) / 15, (Z - A) / 1, length = 30)
looCV_log_lik_b <- numeric(length(b_values))
for (i in seq_along(b_values)) {
current_b <- b_values[i]
# Create histogram object with specified bin width
hx <- hist(x, breaks = seq(A, Z + current_b, by = current_b), plot = FALSE)
# Create step function
hx_f <- stepfun(hx$breaks, c(0, hx$density, 0))
# Calculate f_hat and f_loo
f_hat <- hx_f(x)
f_loo <- (n / (n - 1)) * f_hat - 1 / ((n - 1) * current_b)
# Calculate and store looCV log-likelihood
looCV_log_lik_b[i] <- sum(log(f_loo[f_loo > 0]))
}
# Plot the results
plot(b_values, looCV_log_lik_b, type = "b", pch = 19,
xlab = "Bin Width (b)", ylab = "LOO Log-Likelihood",
main = "LOO Cross-Validation for Bin Width")
# Find the optimal b
optimal_b <- b_values[which.max(looCV_log_lik_b)]
abline(v = optimal_b, col = "red", lty = 2)
legend("topright", legend = paste("Optimal b =", round(optimal_b, 3)), col = "red", lty = 2)
# graph.mixt
# Input:
#    k: number mixture components
#    mu: vector of length k with the mean values of the k normals
#    sigma: vector of length k with the st.dev. values of the k normals
#    alpha: vector of length k with the weights of each normal
#    graphic: logical value indicating if the mixture density must be plotted
#    ...: Other parameters passed to plot()
#
# Output:
#    L, U: extremes of the interval where the mixture density is plotted
#    x: points at which the mixture density is evaluated
#    fx: value of the mixture density at x
#
graph.mixt<-
function(k=1, mu=seq(-2*(k-1),2*(k-1),length=k), sigma=seq(1,1,length=k), alpha=seq(1/k,1/k,length=k), graphic=TRUE,...)
{
L<-min(mu-3*sigma)
U<-max(mu+3*sigma)
x<- seq(from=L,to=U,length=200)
fx<- 0*x
Salpha<-sum(alpha)
for(i in 1:k){
p<-alpha[i]/Salpha
#   	fx <- fx + p*exp(-.5*((x-mu[i])/sigma[i])^2)/(sqrt(2*pi)*sigma[i])
fx <- fx + p*dnorm(x,mu[i],sigma[i])
}
if (graphic){
plot(x,fx,type="l",...)
}
return(list(L = L, U = U, x = x, fx = fx))
}
# sim.mixt
# Input:
#    n: number of simulated data
#    k: number mixture components
#    mu: vector of length k with the mean values of the k normals
#    sigma: vector of length k with the st.dev. values of the k normals
#    alpha: vector of length k with the weights of each normal
#    graphic: logical value indicating if the mixture density and the
#              histogram of the simulated data must be plotted
#    ...: Other parameters passed to plot()
#
# Output:
#    x: simulated data
#
# Requires:
#    graph.mixt
sim.mixt <- function(n=1,k=1,
mu=seq(-2*(k-1),2*(k-1),length=k),
sigma=seq(1,1,length=k),
alpha=seq(1/k,1/k,length=k), graphic=FALSE,...)
{
csa<-cumsum(alpha)
x<-runif(n)
for (i in 1:n){
comp<-sum(csa<=x[i])+1
x[i]<-rnorm(1,mu[comp],sigma[comp])
}
if(graphic) {
out<-graph.mixt(k, mu, sigma, alpha, gr=FALSE)
hist(x,freq = FALSE,
ylim=c(0,max(c(max(out$fx),max(hist(x,plot=FALSE)$density)))))
lines(out$x,out$fx,lty=1,lwd=2)
}
return(x)
}
# Generate 100 observations from f(x) = (3/4)N(x; m = 0, s = 1) +(1/4) N(x; m = 3/2, s = 1/3)
set.seed(123)
n <- 100
mu <- c(0,3/2)
sigma <- c(1,1/3)
alpha <- c(3/4,1/4)
x <- sim.mixt(n=n, k=2, mu=mu, sigma=sigma, alpha=alpha)
f_x <- graph.mixt(k=2, mu=mu, sigma=sigma, alpha=alpha, graphic = F)
#We will use the same method as before
A <- min(x) - 0.05 * diff(range(x))
Z <- max(x) + 0.05 * diff(range(x))
b_values <- seq((Z - A) / 15, (Z - A) / 1, length = 30)
looCV_log_lik_b <- numeric(length(b_values))
for (i in seq_along(b_values)) {
current_b <- b_values[i]
# Create histogram object with specified bin width
hx <- hist(x, breaks = seq(A, Z + current_b, by = current_b), plot = FALSE)
# Create step function
hx_f <- stepfun(hx$breaks, c(0, hx$density, 0))
# Calculate f_hat and f_loo
f_hat <- hx_f(x)
f_loo <- (n / (n - 1)) * f_hat - 1 / ((n - 1) * current_b)
# Calculate and store looCV log-likelihood
looCV_log_lik_b[i] <- sum(log(f_loo[f_loo > 0]))
}
# Plot the results
plot(b_values, looCV_log_lik_b, type = "b", pch = 19,
xlab = "Bin Width (b)", ylab = "LOO Log-Likelihood",
main = "LOO Cross-Validation for Bin Width")
# Find the optimal b
optimal_b <- b_values[which.max(looCV_log_lik_b)]
abline(v = optimal_b, col = "red", lty = 2)
legend("topright", legend = paste("Optimal b =", round(optimal_b, 3)), col = "red", lty = 2)
hx_optimal_b <- hist(x, breaks = seq(A, Z + optimal_b, by = optimal_b), plot = FALSE)
plot(hx_optimal_b, freq = FALSE,
main = paste("Optimal Histogram (b =", round(optimal_b, 3), ")"),
xlab = "CDrate")
lines(f_x$x, f_x$fx, lwd = 2)
scott_b <- 3.49 * sd(x) * (length(x)^(-1/3))
hx_scott_b <- hist(x, breaks = seq(A, Z + scott_b, by = scott_b), plot = FALSE)
ymax <- max(c(hx_scott_b$y, f_x$fx))
plot(hx_scott_b, freq = FALSE, ylim = c(0, ymax),
main = paste("Optimal Histogram (b_scott =", round(scott_b, 3), ")"),
xlab = "CDrate")
lines(f_x$x, f_x$fx, lwd = 2)
n <- length(x)
K0 <- dnorm(0)
kx0 <- density(x)
base_bw <- kx0$bw
h_values <- seq(base_bw/5, base_bw*3, length.out = 50)
loo_loglik_h <- numeric(length(h_values))
for (i in seq_along(h_values)) {
h <- h_values[i]
kx <- density(x, bw = h, kernel = "gaussian", n = 1024,
from = min(x) - 3*h, to = max(x) + 3*h)
kx_f <- approxfun(x = kx$x, y = kx$y, rule = 2)
f_hat <- kx_f(x)                      # approx f_hat at each xi
f_loo <- (n / (n - 1)) * (f_hat - K0 / (n * h))
pos <- f_loo > 0
if (any(pos)) {
loo_loglik_h[i] <- sum(log(f_loo[pos]))
} else {
loo_loglik_h[i] <- -Inf
}
}
optimal_h_approx <- h_values[which.max(loo_loglik_h)]
cat("Optimal h (approx) =", optimal_h_approx, "\n")
hx_optimal_b <- hist(x, breaks = seq(A, Z + optimal_b, by = optimal_b), plot = FALSE)
plot(hx_optimal_b, freq = FALSE,
main = paste("Optimal Histogram (b =", round(optimal_b, 3), ")"),
xlab = "CDrate")
lines(f_x$x, f_x$fx, lwd = 2)
scott_b <- 3.49 * sd(x) * (length(x)^(-1/3))
hx_scott_b <- hist(x, breaks = seq(A, Z + scott_b, by = scott_b), plot = FALSE)
ymax <- max(c(hx_scott_b$y, f_x$fx))
plot(hx_scott_b, freq = FALSE, ylim = c(0, ymax),
main = paste("Optimal Histogram (b_scott =", round(scott_b, 3), ")"),
xlab = "CDrate")
lines(f_x$x, f_x$fx, lwd = 2)
# Compute histogram densities as step functions
hx_scott_f <- stepfun(hx_scott_b$breaks, c(0, hx_scott_b$density, 0))
hx_optimal_f <- stepfun(hx_optimal_b$breaks, c(0, hx_optimal_b$density, 0))
# Evaluate histogram estimates at the grid of f_x
f_hat_scott <- hx_scott_f(f_x$x)
f_hat_optimal <- hx_optimal_f(f_x$x)
# Compute MSE for Scott's rule and Optimal b
mse_scott <- mean((f_hat_scott - f_x$fx)^2)
mse_optimal <- mean((f_hat_optimal - f_x$fx)^2)
# Print results
cat("MSE (Scott's rule):", mse_scott, "\n")
cat("MSE (Optimal b):", mse_optimal, "\n")
# Compute histogram densities as step functions
hx_scott_f <- stepfun(hx_scott_b$breaks, c(0, hx_scott_b$density, 0))
hx_optimal_f <- stepfun(hx_optimal_b$breaks, c(0, hx_optimal_b$density, 0))
# Evaluate histogram estimates at the grid of f_x
f_hat_scott <- hx_scott_f(x)
f_hat_optimal <- hx_optimal_f(x)
# Compute MSE for Scott's rule and Optimal b
mse_scott <- mean((f_hat_scott - f_x$fx)^2)
mse_optimal <- mean((f_hat_optimal - f_x$fx)^2)
# Print results
cat("MSE (Scott's rule):", mse_scott, "\n")
cat("MSE (Optimal b):", mse_optimal, "\n")
# Compute histogram densities as step functions
hx_scott_f <- stepfun(hx_scott_b$breaks, c(0, hx_scott_b$density, 0))
hx_optimal_f <- stepfun(hx_optimal_b$breaks, c(0, hx_optimal_b$density, 0))
# Evaluate histogram estimates at the grid of f_x
f_hat_scott <- hx_scott_f(f_x$x)
f_hat_optimal <- hx_optimal_f(f_x$x)
# Compute MSE for Scott's rule and Optimal b
mse_scott <- mean((f_hat_scott - f_x$fx)^2)
mse_optimal <- mean((f_hat_optimal - f_x$fx)^2)
# Print results
cat("MSE (Scott's rule):", mse_scott, "\n")
cat("MSE (Optimal b):", mse_optimal, "\n")
n <- length(x)
K0 <- dnorm(0)
kx0 <- density(x)
base_bw <- kx0$bw
h_values <- seq(base_bw/5, base_bw*3, length.out = 50)
loo_loglik_h <- numeric(length(h_values))
for (i in seq_along(h_values)) {
h <- h_values[i]
kx <- density(x, bw = h, kernel = "gaussian", n = 1024,
from = min(x) - 3*h, to = max(x) + 3*h)
kx_f <- approxfun(x = kx$x, y = kx$y, rule = 2)
f_hat <- kx_f(x)                      # approx f_hat at each xi
f_loo <- (n / (n - 1)) * (f_hat - K0 / (n * h))
pos <- f_loo > 0
if (any(pos)) {
loo_loglik_h[i] <- sum(log(f_loo[pos]))
} else {
loo_loglik_h[i] <- -Inf
}
}
optimal_h_approx <- h_values[which.max(loo_loglik_h)]
cat("Optimal h (approx) =", optimal_h_approx, "\n")
plot(h_values, loo_loglik_h, type = "b", pch = 19,
xlab = "Bandwidth (h)", ylab = "LOO log-likelihood",
main = "LOO CV for KDE bandwidth (approx)")
abline(v = optimal_h_approx, col = "red", lty = 2)
legend("bottomright", legend = paste("optimal h =", round(optimal_h_approx, 4)),
col = "red", lty = 2)
kx_opt <- density(x, bw = optimal_h_approx, kernel = "gaussian")
# Common ylim so both functions fit inside the plot
ymax <- max(c(kx_opt$y, f_x$fx))
plot(kx_opt,
ylim = c(0, ymax),
main = paste("KDE (h =", round(optimal_h_approx, 4), ")"),
col = "blue",
lwd = 2)
lines(f_x$x, f_x$fx, col = "black", lwd = 2)
legend("topright",
legend = c("KDE", "f(x)"),
col = c("blue", "black"),
lwd = 2,
bty = "n")
# Generate 100 observations from f(x) = (3/4)N(x; m = 0, s = 1) +(1/4) N(x; m = 3/2, s = 1/3)
set.seed(123)
n <- 100
mu <- c(0,3/2)
sigma <- c(1,1/3)
alpha <- c(3/4,1/4)
x <- sim.mixt(n=n, k=2, mu=mu, sigma=sigma, alpha=alpha)
f_x <- graph.mixt(k=2, mu=mu, sigma=sigma, alpha=alpha, graphic = F)
scott_b <- 3.49 * sd(x) * (length(x)^(-1/3))
hx_scott_b <- hist(x, breaks = seq(A, Z + scott_b, by = scott_b), plot = FALSE)
ymax <- max(c(hx_scott_b$y, f_x$fx))
plot(hx_scott_b, freq = FALSE, ylim = c(0, ymax),
main = paste("Optimal Histogram (b_scott =", round(scott_b, 3), ")"),
xlab = "CDrate")
lines(f_x$x, f_x$fx, lwd = 2)
# Compute histogram densities as step functions
hx_scott_f <- stepfun(hx_scott_b$breaks, c(0, hx_scott_b$density, 0))
hx_optimal_f <- stepfun(hx_optimal_b$breaks, c(0, hx_optimal_b$density, 0))
# Evaluate histogram estimates at the grid of f_x
f_hat_scott <- hx_scott_f(x)
f_hat_optimal <- hx_optimal_f(x)
# Compute MSE for Scott's rule and Optimal b
mse_scott <- mean((f_hat_scott - f_x$fx)^2)
mse_optimal <- mean((f_hat_optimal - f_x$fx)^2)
# Print results
cat("MSE (Scott's rule):", mse_scott, "\n")
cat("MSE (Optimal b):", mse_optimal, "\n")
# Compute histogram densities as step functions
hx_scott_f <- stepfun(hx_scott_b$breaks, c(0, hx_scott_b$density, 0))
hx_optimal_f <- stepfun(hx_optimal_b$breaks, c(0, hx_optimal_b$density, 0))
# Evaluate histogram estimates at the grid of f_x
f_hat_scott <- hx_scott_f(f_x$x)
f_hat_optimal <- hx_optimal_f(f_x$x)
# Compute MSE for Scott's rule and Optimal b
mse_scott <- mean((f_hat_scott - f_x$fx)^2)
mse_optimal <- mean((f_hat_optimal - f_x$fx)^2)
# Print results
cat("MSE (Scott's rule):", mse_scott, "\n")
cat("MSE (Optimal b):", mse_optimal, "\n")
set.seed(123)
# Parametri della miscela
n <- 100
mu <- c(0, 3/2)
sigma <- c(1, 1/3)
alpha <- c(3/4, 1/4)
R <- 500   # numero di repliche Monte Carlo
# Griglia di valutazione (uguale alla densità vera f_x)
f_x <- graph.mixt(k=2, mu=mu, sigma=sigma, alpha=alpha, graphic = FALSE)
grid <- f_x$x
true_density <- f_x$fx
# Matrici per salvare le stime
est_scott <- matrix(NA, nrow=R, ncol=length(grid))
est_opt   <- matrix(NA, nrow=R, ncol=length(grid))
for (r in 1:R) {
# Simula dati
x <- sim.mixt(n=n, k=2, mu=mu, sigma=sigma, alpha=alpha)
# Scott's rule bin width
scott_b <- 3.49 * sd(x) * (length(x)^(-1/3))
hx_scott_b <- hist(x, breaks = seq(min(x), max(x) + scott_b, by = scott_b), plot = FALSE)
hx_scott_f <- stepfun(hx_scott_b$breaks, c(0, hx_scott_b$density, 0))
est_scott[r, ] <- hx_scott_f(grid)
# Optimal b (CV log-likelihood)
A <- min(x) - 0.05 * diff(range(x))
Z <- max(x) + 0.05 * diff(range(x))
b_values <- seq((Z - A)/15, (Z - A)/1, length=30)
looCV_log_lik_b <- numeric(length(b_values))
for (i in seq_along(b_values)) {
current_b <- b_values[i]
hx <- hist(x, breaks = seq(A, Z + current_b, by = current_b), plot = FALSE)
hx_f <- stepfun(hx$breaks, c(0, hx$density, 0))
f_hat <- hx_f(x)
f_loo <- (n/(n-1)) * f_hat - 1/((n-1)*current_b)
looCV_log_lik_b[i] <- sum(log(f_loo[f_loo > 0]))
}
optimal_b <- b_values[which.max(looCV_log_lik_b)]
hx_optimal_b <- hist(x, breaks = seq(A, Z + optimal_b, by = optimal_b), plot = FALSE)
hx_optimal_f <- stepfun(hx_optimal_b$breaks, c(0, hx_optimal_b$density, 0))
est_opt[r, ] <- hx_optimal_f(grid)
}
# --- Calcolo Bias, Varianza, MSE ---
# Scott
mean_scott <- colMeans(est_scott)
bias2_scott <- mean((mean_scott - true_density)^2)
var_scott <- mean(apply(est_scott, 2, var))
mse_scott <- bias2_scott + var_scott
# Ottimale
mean_opt <- colMeans(est_opt)
bias2_opt <- mean((mean_opt - true_density)^2)
var_opt <- mean(apply(est_opt, 2, var))
mse_opt <- bias2_opt + var_opt
# Risultati
cat("Scott:\n",
" Bias^2 =", bias2_scott, "\n",
" Var    =", var_scott, "\n",
" MSE    =", mse_scott, "\n\n")
cat("Optimal b:\n",
" Bias^2 =", bias2_opt, "\n",
" Var    =", var_opt, "\n",
" MSE    =", mse_opt, "\n")
